{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0d9dc56",
   "metadata": {},
   "source": [
    "## TFRecord Decoding Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e652e4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import io\n",
    "from collections import namedtuple\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8377c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_feature_description = {\n",
    "    'height': tf.io.FixedLenFeature(shape = (), dtype = np.int64),\n",
    "    'width' : tf.io.FixedLenFeature(shape = (), dtype = np.int64),\n",
    "    'filename' : tf.io.FixedLenFeature(shape = (), dtype = tf.string),\n",
    "    'image' : tf.io.FixedLenFeature(shape = (), dtype = tf.string),\n",
    "    'object/bbox/xmin': tf.io.FixedLenSequenceFeature(shape = (), dtype = np.float32, allow_missing = True),\n",
    "    'object/bbox/xmax': tf.io.FixedLenSequenceFeature(shape = (), dtype = np.float32, allow_missing = True),\n",
    "    'object/bbox/ymin': tf.io.FixedLenSequenceFeature(shape = (), dtype = np.float32, allow_missing = True),\n",
    "    'object/bbox/ymax': tf.io.FixedLenSequenceFeature(shape = (), dtype = np.float32, allow_missing = True),\n",
    "    'object/class/text':tf.io.FixedLenSequenceFeature(shape = (), dtype = tf.string, allow_missing = True),\n",
    "    'object/class/label':tf.io.FixedLenSequenceFeature(shape = (), dtype = np.int64, allow_missing = True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07f8f1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_feature_description = {\n",
    "    'image/height': tf.io.FixedLenFeature(shape = (), dtype = np.int64),\n",
    "    'image/width' : tf.io.FixedLenFeature(shape = (), dtype = np.int64),\n",
    "    'image/filename' : tf.io.FixedLenFeature(shape = (), dtype = tf.string),\n",
    "    'image/encoded' : tf.io.FixedLenFeature(shape = (), dtype = tf.string),\n",
    "    'image/object/bbox/xmin': tf.io.FixedLenSequenceFeature(shape = (), dtype = np.float32, allow_missing = True),\n",
    "    'image/object/bbox/xmax': tf.io.FixedLenSequenceFeature(shape = (), dtype = np.float32, allow_missing = True),\n",
    "    'image/object/bbox/ymin': tf.io.FixedLenSequenceFeature(shape = (), dtype = np.float32, allow_missing = True),\n",
    "    'image/object/bbox/ymax': tf.io.FixedLenSequenceFeature(shape = (), dtype = np.float32, allow_missing = True),\n",
    "    'image/object/class/text':tf.io.FixedLenSequenceFeature(shape = (), dtype = tf.string, allow_missing = True),\n",
    "    'image/object/class/label':tf.io.FixedLenSequenceFeature(shape = (), dtype = np.int64, allow_missing = True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da69ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_data(unparsed_example):\n",
    "    return tf.io.parse_single_example(unparsed_example, image_feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebe89cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytestring(parsed_example):\n",
    "    print(type(parsed_example))\n",
    "    byte_string = parsed_example['image/encoded']\n",
    "    image = tf.io.decode_image(byte_string)\n",
    "    image = tf.reshape(image, [parsed_example['image/height'], parsed_example['image/width'], 3])\n",
    "    parsed_example['image/encoded'] = image\n",
    "    bbox = tf.stack([parsed_example['image/object/bbox/ymin'], parsed_example['image/object/bbox/xmin'], parsed_example['image/object/bbox/ymax'], parsed_example['image/object/bbox/xmax']], axis = -1)\n",
    "    output_dict = {'image': image,\n",
    "                  'objects': {\n",
    "                      'bbox': bbox,\n",
    "                      'label':parsed_example['image/object/class/label']\n",
    "                  }}\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce136647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfrecord_decoder(tfrecord_path):\n",
    "    dataset = tf.data.TFRecordDataset('./train.tfrecord')\n",
    "    dataset = dataset.map(_parse_data)\n",
    "    dataset = dataset.map(_bytestring)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19ff729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57ae051c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3903dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d56da154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': <tf.Tensor: shape=(300, 300, 3), dtype=uint8, numpy=\n",
      "array([[[187, 215, 236],\n",
      "        [187, 215, 236],\n",
      "        [187, 215, 236],\n",
      "        ...,\n",
      "        [185, 212, 231],\n",
      "        [185, 212, 231],\n",
      "        [185, 212, 231]],\n",
      "\n",
      "       [[186, 214, 235],\n",
      "        [187, 215, 236],\n",
      "        [188, 216, 237],\n",
      "        ...,\n",
      "        [186, 213, 232],\n",
      "        [186, 213, 232],\n",
      "        [186, 213, 232]],\n",
      "\n",
      "       [[186, 214, 235],\n",
      "        [187, 215, 236],\n",
      "        [188, 216, 237],\n",
      "        ...,\n",
      "        [186, 213, 232],\n",
      "        [186, 213, 232],\n",
      "        [185, 212, 231]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 44,  45,  39],\n",
      "        [ 53,  54,  46],\n",
      "        [ 51,  53,  42],\n",
      "        ...,\n",
      "        [ 68,  54,  27],\n",
      "        [150, 129,  82],\n",
      "        [159, 137,  79]],\n",
      "\n",
      "       [[ 34,  35,  29],\n",
      "        [ 52,  53,  45],\n",
      "        [ 58,  60,  49],\n",
      "        ...,\n",
      "        [ 55,  43,  17],\n",
      "        [141, 123,  75],\n",
      "        [157, 136,  79]],\n",
      "\n",
      "       [[ 29,  30,  24],\n",
      "        [ 53,  54,  46],\n",
      "        [ 63,  64,  56],\n",
      "        ...,\n",
      "        [ 41,  29,   3],\n",
      "        [129, 111,  65],\n",
      "        [144, 123,  66]]], dtype=uint8)>, 'objects': {'bbox': <tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
      "array([[0.04333333, 0.21      , 0.8233333 , 0.60333335],\n",
      "       [0.04333333, 0.71      , 0.8233333 , 1.        ]], dtype=float32)>, 'label': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([20, 22], dtype=int64)>}}\n"
     ]
    }
   ],
   "source": [
    "for ex in dataset:\n",
    "    print(ex)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32400c78",
   "metadata": {},
   "source": [
    "### Useless Undefined Code Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42a0484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature={\n",
    "#         'image/height': int64_feature(height),\n",
    "#         'image/width': int64_feature(width),\n",
    "#         'image/filename': bytes_feature(filename),\n",
    "#         'image/source_id': bytes_feature(filename),\n",
    "#         'image/encoded': bytes_feature(encoded_jpg),\n",
    "#         'image/format': bytes_feature(image_format),\n",
    "#         'image/object/bbox/xmin': float_list_feature(xmins),\n",
    "#         'image/object/bbox/xmax': float_list_feature(xmaxs),\n",
    "#         'image/object/bbox/ymin': float_list_feature(ymins),\n",
    "#         'image/object/bbox/ymax': float_list_feature(ymaxs),\n",
    "#         'image/object/class/text': bytes_list_feature(classes_text),\n",
    "#         'image/object/class/label': int64_list_feature(classes),\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c9e47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = tfds.features.FeaturesDict({\n",
    "#     'image/height': tfds.features.Scalar(dtype = np.int64),\n",
    "#     'image/width' : tfds.features.Scalar(dtype = np.int64),\n",
    "#     'image/filename': tfds.features.Scalar(dtype = tf.string),\n",
    "#     'image/source_id': tfds.features.Scalar(dtype = tf.string),\n",
    "#     'image/encoded' : tfds.features.Image(shape = (300, 300, 3)),\n",
    "#     'image/format' : tfds.features.Scalar(dtype = tf.string),\n",
    "#     'image/object/bbox': tfds.features.Sequence({\n",
    "#         'xmin': tfds.features.Tensor(shape=(), dtype = np.float32),\n",
    "#         'xmax': tfds.features.Tensor(shape=(), dtype = np.float32),\n",
    "#         'ymin': tfds.features.Tensor(shape=(), dtype = np.float32),\n",
    "#         'ymax': tfds.features.Tensor(shape=(), dtype = np.float32),\n",
    "#     }),\n",
    "#     'image/object/class':tfds.features.Sequence({\n",
    "#         'text': tfds.features.Tensor(shape = (), dtype = tf.string),\n",
    "#         'label':tfds.features.Tensor(shape = (), dtype = np.int64)\n",
    "        \n",
    "#     })\n",
    "    \n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f50aeba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_infos = [\n",
    "#     tfds.core.SplitInfo(\n",
    "#         name = 'monument-train',\n",
    "#         shard_lengths = [506],\n",
    "#         num_bytes = 0),\n",
    "#     tfds.core.SplitInfo(\n",
    "#         name = 'monument-test',\n",
    "#         shard_lengths = [173],\n",
    "#         num_bytes = 0\n",
    "#     )\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1236d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_infos = tfds.folder_dataset.compute_split_info(out_dir = './Monument Dataset',\n",
    "# filename_template = tfds.core.ShardedFileTemplate(data_dir = './Monument Dataset', template = '{SPLIT}.{FILEFORMAT}-{SHARD_X_OF_Y}')\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a7311a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfds.folder_dataset.write_metadata(\n",
    "#     data_dir = './Monument Dataset',\n",
    "#     features = features,\n",
    "#     split_infos = split_infos,\n",
    "#     filename_template = '{SPLIT}.{FILEFORMAT}-{SHARD_X_OF_Y}'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd7ed938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# builder = tfds.builder_from_directory('./Monument Dataset')\n",
    "# builder.info.splits['monument-train'].num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1a3508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = builder.as_dataset(split = 'monument-train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67769068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature={\n",
    "#         'image/height': int64_feature(height),\n",
    "#         'image/width': int64_feature(width),\n",
    "#         'image/filename': bytes_feature(filename),\n",
    "#         'image/source_id': bytes_feature(filename),\n",
    "#         'image/encoded': bytes_feature(encoded_jpg),\n",
    "#         'image/format': bytes_feature(image_format),\n",
    "#         'image/object/bbox/xmin': float_list_feature(xmins),\n",
    "#         'image/object/bbox/xmax': float_list_feature(xmaxs),\n",
    "#         'image/object/bbox/ymin': float_list_feature(ymins),\n",
    "#         'image/object/bbox/ymax': float_list_feature(ymaxs),\n",
    "#         'image/object/class/text': bytes_list_feature(classes_text),\n",
    "#         'image/object/class/label': int64_list_feature(classes),\n",
    "#     }\n",
    "\n",
    "#         'height': int64_feature(height),\n",
    "#         'width': int64_feature(width),\n",
    "#         'filename': bytes_feature(filename),\n",
    "#         'image': bytes_feature(encoded_jpg),\n",
    "#         'object/bbox/xmin': float_list_feature(xmins),\n",
    "#         'object/bbox/xmax': float_list_feature(xmaxs),\n",
    "#         'object/bbox/ymin': float_list_feature(ymins),\n",
    "#         'object/bbox/ymax': float_list_feature(ymaxs),\n",
    "#         'object/class/text': bytes_list_feature(classes_text),\n",
    "#         'object/class/label': int64_list_feature(classes),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5149247f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
